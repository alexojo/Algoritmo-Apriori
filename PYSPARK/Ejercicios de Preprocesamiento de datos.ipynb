{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c217c63",
   "metadata": {},
   "source": [
    "# Ejercicios de Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4342df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c909323",
   "metadata": {},
   "source": [
    "1. ESTANDARIZACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8a438bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ESTANDARIZACION(data):\n",
    "    \n",
    "    # Hallamos el valor de la desviacion estandar y media\n",
    "    desviacion_estandar = data.stdev()\n",
    "    media = data.mean()\n",
    "    # Realizamos la estandarizacion de cada elemento, con map\n",
    "    estandarizado = data.map(lambda x: (x-media)/(desviacion_estandar))\n",
    "    # Retornamos la data normalizada\n",
    "    return estandarizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5cc405d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1.5374271566044004,\n",
       " -1.2821562324889528,\n",
       " -0.9630675773446432,\n",
       " -0.6439789222003337,\n",
       " -0.3248902670560242,\n",
       " -0.005801611911714657,\n",
       " 0.3132870432325949,\n",
       " 0.6323756983769044,\n",
       " 0.951464353521214,\n",
       " 1.2705530086655235,\n",
       " 1.589641663809833]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos nuestra data de un arreglo de numeros\n",
    "data = [1,5,10,15,20,25,30,35,40,45,50]\n",
    "# Volvemos este arreglo de números en un RDD de 3 particiones\n",
    "dataRDD = sc.parallelize(data,3)\n",
    "estandarizacion = ESTANDARIZACION(dataRDD)\n",
    "\n",
    "# NORMALIZACION\n",
    "estandarizacion.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a05a72",
   "metadata": {},
   "source": [
    "2. ESCALONAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b36fb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ESCALONAMIENTO(data):\n",
    "    \n",
    "    # Hallamos el valor maximo y minimo de la data\n",
    "    maxval = data.max()\n",
    "    minval = data.min()\n",
    "    # Realizamos el escalonamiento de cada elemento, con map\n",
    "    escalonado = data.map(lambda x: (x-minval)/(maxval-minval))\n",
    "    # Retornamos la data normalizada\n",
    "    return escalonado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c8154d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.08163265306122448,\n",
       " 0.1836734693877551,\n",
       " 0.2857142857142857,\n",
       " 0.3877551020408163,\n",
       " 0.4897959183673469,\n",
       " 0.5918367346938775,\n",
       " 0.6938775510204082,\n",
       " 0.7959183673469388,\n",
       " 0.8979591836734694,\n",
       " 1.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos nuestra data de un arreglo de numeros\n",
    "data = [1,5,10,15,20,25,30,35,40,45,50]\n",
    "# Volvemos este arreglo de números en un RDD de 3 particiones\n",
    "dataRDD = sc.parallelize(data,3)\n",
    "escalonamiento = ESCALONAMIENTO(dataRDD)\n",
    "\n",
    "# NORMALIZACION\n",
    "escalonamiento.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256fb0eb",
   "metadata": {},
   "source": [
    "3. NORMALIZACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eac302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NORMALIZACION(data):\n",
    "    \n",
    "    # Hallamos la norma a la data\n",
    "    aux = data.map(lambda x:x**2).sum()\n",
    "    norma = math.sqrt(aux)\n",
    "    # Realizamos la normalización de cada elemento, con map\n",
    "    normalizado = data.map(lambda x: x/norma)\n",
    "    # Retornamos la data normalizada\n",
    "    return normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2a32a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.010192414366433438,\n",
       " 0.050962071832167194,\n",
       " 0.10192414366433439,\n",
       " 0.15288621549650158,\n",
       " 0.20384828732866878,\n",
       " 0.25481035916083594,\n",
       " 0.30577243099300316,\n",
       " 0.35673450282517033,\n",
       " 0.40769657465733755,\n",
       " 0.4586586464895047,\n",
       " 0.5096207183216719]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos nuestra data de un arreglo de numeros\n",
    "data = [1,5,10,15,20,25,30,35,40,45,50]\n",
    "# Volvemos este arreglo de números en un RDD de 3 particiones\n",
    "dataRDD = sc.parallelize(data,3)\n",
    "normalizacion = NORMALIZACION(dataRDD)\n",
    "\n",
    "# NORMALIZACION\n",
    "normalizacion.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4fd212",
   "metadata": {},
   "source": [
    "4. TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c416eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF(oraciones):\n",
    "    \n",
    "    # Tokenizamos cada oracion, y le agregamos una nueva variable para el conteo de apariciones\n",
    "    mapeo = oraciones.flatMap(lambda x: [((x[0],i),1) for i in x[1].split()])\n",
    "\n",
    "    # Agruparemos los pares key-value comunes, y agregaremos los valores de la misma para oftener sus apariciones\n",
    "    reducir = mapeo.reduceByKey(lambda x,y:x+y)\n",
    "\n",
    "    # APlicaremos la formula de tf para cada token , en cada documento\n",
    "    tf = reducir.map(lambda x: (x[0][1], (x[0][0],(1 + math.log10(x[1]/(len(data[x[0][0]-1][1].split(\" \"))))))))\n",
    "    reducir2 = reducir.map(lambda x: ((x[0][0],x[0][1]), (1 + math.log10(x[1]/(len(data[x[0][0]][1].split(\" \"))))) ))\n",
    "\n",
    "    # Visualizacion de los tokens con sus valores TF\n",
    "    muestra = reducir.map(lambda x: (x[0][1], \"doc-\"+str(x[0][0]),(1 + math.log10(x[1]/(len(data[x[0][0]][1].split(\" \")))))))\n",
    "    \n",
    "    return tf, reducir2, muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8320f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('el', 'doc-0', 0.09691001300805646),\n",
       " ('bueno', 'doc-0', 0.09691001300805646),\n",
       " ('en', 'doc-0', 0.09691001300805646),\n",
       " ('mineria', 'doc-0', 0.09691001300805646),\n",
       " ('datos', 'doc-0', 0.09691001300805646),\n",
       " ('sabe', 'doc-1', 0.09691001300805646),\n",
       " ('minerar', 'doc-1', 0.09691001300805646),\n",
       " ('librerias', 'doc-1', 0.09691001300805646),\n",
       " ('de', 'doc-1', 0.09691001300805646),\n",
       " ('es', 'doc-0', 0.09691001300805646),\n",
       " ('muy', 'doc-0', 0.09691001300805646),\n",
       " ('de', 'doc-0', 0.09691001300805646),\n",
       " ('el', 'doc-1', 0.09691001300805646),\n",
       " ('datos', 'doc-1', 0.3979400086720376),\n",
       " ('con', 'doc-1', 0.09691001300805646)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos nuestra data de dos oraciones\n",
    "data=[(0,\"el es muy bueno en mineria de datos\"),\n",
    "      (1,\"el sabe minerar datos con librerias de datos\")]\n",
    "\n",
    "# Volvemos este arreglo de tuplas en un RDD de 2 particiones\n",
    "oraciones=sc.parallelize(data,2)\n",
    "oraciones.collect()\n",
    "\n",
    "# TF\n",
    "tf = TF(oraciones)\n",
    "tf[2].collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e198277",
   "metadata": {},
   "source": [
    "5. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "420df8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF_IDF(reducir2, tf):\n",
    "    \n",
    "    # Asignamos los pares key-value a uno nuevo, el key será el token, value será TF y un auxiliar(1)\n",
    "    mapeo2=reducir2.map(lambda x: (x[0][1],(x[0][0],x[1],1)))\n",
    "\n",
    "    # Extraemos el token y auxiliar, esto nos ayudará a identificar la ocurrencia en las oraciones\n",
    "    mapeo3=mapeo2.map(lambda x:(x[0],x[1][2]))\n",
    "\n",
    "    # Reducimos por key, para obtener el conteo de apariciones en el documento\n",
    "    reducir3=mapeo3.reduceByKey(lambda x,y:x+y)\n",
    "\n",
    "    # Calcularemos el valor de IDF\n",
    "    idf=reducir3.map(lambda x: (x[0],math.log10(1 + len(data)/x[1])))\n",
    "\n",
    "    # RightOuterJoin entre valores tf y idf para unir el TF y IDF de cada token\n",
    "    join = tf.rightOuterJoin(idf)\n",
    "\n",
    "    # Multiplicamos los valores de TF y IDF para obtener TF-IDF\n",
    "    tfidf = join.map(lambda x: (x[0],\"doc-\"+str(x[1][0][0]), x[1][0][1]*x[1][1]))\n",
    "\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eccb2a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('el', 'doc-0', 0.0291728207956116),\n",
       " ('el', 'doc-1', 0.0291728207956116),\n",
       " ('datos', 'doc-0', 0.0291728207956116),\n",
       " ('datos', 'doc-1', 0.11979187908506812),\n",
       " ('con', 'doc-1', 0.04623782700130271),\n",
       " ('sabe', 'doc-1', 0.04623782700130271),\n",
       " ('minerar', 'doc-1', 0.04623782700130271),\n",
       " ('librerias', 'doc-1', 0.04623782700130271),\n",
       " ('es', 'doc-0', 0.04623782700130271),\n",
       " ('bueno', 'doc-0', 0.04623782700130271),\n",
       " ('en', 'doc-0', 0.04623782700130271),\n",
       " ('mineria', 'doc-0', 0.04623782700130271),\n",
       " ('de', 'doc-1', 0.0291728207956116),\n",
       " ('de', 'doc-0', 0.0291728207956116),\n",
       " ('muy', 'doc-0', 0.04623782700130271)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos nuestra data de dos oraciones\n",
    "data=[(0,\"el es muy bueno en mineria de datos\"),\n",
    "      (1,\"el sabe minerar datos con librerias de datos\")]\n",
    "\n",
    "# Volvemos este arreglo de tuplas en un RDD de 2 particiones\n",
    "oraciones=sc.parallelize(data,2)\n",
    "oraciones.collect()\n",
    "\n",
    "# TF-IDF\n",
    "tf = TF(oraciones) # Aplicamos tf\n",
    "tfidf = TF_IDF(tf[1],tf[0]) # Aplicamos tfidf con el tf anterior\n",
    "tfidf.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
