{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53bd3af5",
   "metadata": {},
   "source": [
    "# Algoritmos de Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "901bb466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da38aeb",
   "metadata": {},
   "source": [
    "## BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd51123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BAG_OF_WORDS(data):\n",
    "    \n",
    "    # Tokenizacion de la data, y conversion a lowercase\n",
    "    tokens=data.flatMap(lambda x: [(i.lower(),len(i)) for i in x[1].split()])\n",
    "    # Agrupamos las keys\n",
    "    mapeo=tokens.groupByKey()\n",
    "    bow=mapeo.map(lambda x: x[0])\n",
    "    # Filtramos a aquellas keys que tengan un tamanio mayor a '2'\n",
    "    bow = bow.filter(lambda x: len(x) > 2)\n",
    "    \n",
    "    return bow\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c4d700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bueno', 'mineria', 'datos', 'con', 'muy', 'sabe', 'minerar', 'librerias']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos nuestra data de dos oraciones\n",
    "data=[(0,\"el es muy bueno en mineria de datos\"),\n",
    "      (1,\"el sabe minerar datos con librerias de datos\")]\n",
    "\n",
    "# Volvemos este arreglo de tuplas en un RDD de 2 particiones\n",
    "oraciones=sc.parallelize(data,2)\n",
    "\n",
    "# BAG OF WORDS\n",
    "bow = BAG_OF_WORDS(oraciones)\n",
    "bow.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff743161",
   "metadata": {},
   "source": [
    "# TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef25567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF(oraciones):\n",
    "    \n",
    "    # Tokenizamos cada oracion, y le agregamos una nueva variable para el conteo de apariciones\n",
    "    mapeo = oraciones.flatMap(lambda x: [((x[0],i),1) for i in x[1].split()])\n",
    "\n",
    "    # Agruparemos los pares key-value comunes, y agregaremos los valores de la misma para oftener sus apariciones\n",
    "    reducir = mapeo.reduceByKey(lambda x,y:x+y)\n",
    "\n",
    "    # APlicaremos la formula de tf para cada token , en cada documento\n",
    "    tf = reducir.map(lambda x: (x[0][1], (x[0][0],(1 + math.log10(x[1]/(len(data[x[0][0]-1][1].split(\" \"))))))))\n",
    "    reducir2 = reducir.map(lambda x: ((x[0][0],x[0][1]), (1 + math.log10(x[1]/(len(data[x[0][0]][1].split(\" \"))))) ))\n",
    "\n",
    "    # Visualizacion de los tokens con sus valores TF\n",
    "    muestra = reducir.map(lambda x: (x[0][1], \"doc-\"+str(x[0][0]),(1 + math.log10(x[1]/(len(data[x[0][0]][1].split(\" \")))))))\n",
    "    \n",
    "    return tf, reducir2, muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d3ecc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------------+\n",
      "|    Token|DocumentoID|                 TF|\n",
      "+---------+-----------+-------------------+\n",
      "|       el|      doc-0|0.09691001300805646|\n",
      "|    bueno|      doc-0|0.09691001300805646|\n",
      "|       en|      doc-0|0.09691001300805646|\n",
      "|  mineria|      doc-0|0.09691001300805646|\n",
      "|    datos|      doc-0|0.09691001300805646|\n",
      "|     sabe|      doc-1|0.09691001300805646|\n",
      "|  minerar|      doc-1|0.09691001300805646|\n",
      "|librerias|      doc-1|0.09691001300805646|\n",
      "|       de|      doc-1|0.09691001300805646|\n",
      "|       es|      doc-0|0.09691001300805646|\n",
      "|      muy|      doc-0|0.09691001300805646|\n",
      "|       de|      doc-0|0.09691001300805646|\n",
      "|       el|      doc-1|0.09691001300805646|\n",
      "|    datos|      doc-1| 0.3979400086720376|\n",
      "|      con|      doc-1|0.09691001300805646|\n",
      "+---------+-----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos nuestra data de dos oraciones\n",
    "data=[(0,\"el es muy bueno en mineria de datos\"),\n",
    "      (1,\"el sabe minerar datos con librerias de datos\")]\n",
    "\n",
    "# Volvemos este arreglo de tuplas en un RDD de 2 particiones\n",
    "oraciones=sc.parallelize(data,2)\n",
    "oraciones.collect()\n",
    "\n",
    "# TF\n",
    "tf = TF(oraciones)\n",
    "tf[2].collect()\n",
    "\n",
    "# Visualizacion de TF en tabla\n",
    "hasattr(tf[2], \"toDF\")\n",
    "spark = SparkSession(sc)\n",
    "hasattr(tf[2], \"toDF\")\n",
    "tf[2].toDF([\"Token\",\"DocumentoID\",\"TF\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5ba573",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "027eba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF_IDF(reducir2, tf):\n",
    "    \n",
    "    # Asignamos los pares key-value a uno nuevo, el key será el token, value será TF y un auxiliar(1)\n",
    "    mapeo2=reducir2.map(lambda x: (x[0][1],(x[0][0],x[1],1)))\n",
    "\n",
    "    # Extraemos el token y auxiliar, esto nos ayudará a identificar la ocurrencia en las oraciones\n",
    "    mapeo3=mapeo2.map(lambda x:(x[0],x[1][2]))\n",
    "\n",
    "    # Reducimos por key, para obtener el conteo de apariciones en el documento\n",
    "    reducir3=mapeo3.reduceByKey(lambda x,y:x+y)\n",
    "\n",
    "    # Calcularemos el valor de IDF\n",
    "    idf=reducir3.map(lambda x: (x[0],math.log10(1 + len(data)/x[1])))\n",
    "\n",
    "    # RightOuterJoin entre valores tf y idf para unir el TF y IDF de cada token\n",
    "    join = tf.rightOuterJoin(idf)\n",
    "\n",
    "    # Multiplicamos los valores de TF y IDF para obtener TF-IDF\n",
    "    tfidf = join.map(lambda x: (x[0],\"doc-\"+str(x[1][0][0]), x[1][0][1]*x[1][1]))\n",
    "\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "760de29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------------+\n",
      "|    Token|DocumentoID|             TF-IDF|\n",
      "+---------+-----------+-------------------+\n",
      "|       el|      doc-0| 0.0291728207956116|\n",
      "|       el|      doc-1| 0.0291728207956116|\n",
      "|    datos|      doc-0| 0.0291728207956116|\n",
      "|    datos|      doc-1|0.11979187908506812|\n",
      "|      con|      doc-1|0.04623782700130271|\n",
      "|     sabe|      doc-1|0.04623782700130271|\n",
      "|  minerar|      doc-1|0.04623782700130271|\n",
      "|librerias|      doc-1|0.04623782700130271|\n",
      "|       es|      doc-0|0.04623782700130271|\n",
      "|    bueno|      doc-0|0.04623782700130271|\n",
      "|       en|      doc-0|0.04623782700130271|\n",
      "|  mineria|      doc-0|0.04623782700130271|\n",
      "|       de|      doc-1| 0.0291728207956116|\n",
      "|       de|      doc-0| 0.0291728207956116|\n",
      "|      muy|      doc-0|0.04623782700130271|\n",
      "+---------+-----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creamos nuestra data de dos oraciones\n",
    "data=[(0,\"el es muy bueno en mineria de datos\"),\n",
    "      (1,\"el sabe minerar datos con librerias de datos\")]\n",
    "\n",
    "# Volvemos este arreglo de tuplas en un RDD de 2 particiones\n",
    "oraciones=sc.parallelize(data,2)\n",
    "oraciones.collect()\n",
    "\n",
    "# TF-IDF\n",
    "tf = TF(oraciones) # Aplicamos tf\n",
    "tfidf = TF_IDF(tf[1],tf[0]) # Aplicamos tfidf con el tf anterior\n",
    "\n",
    "# Visualizacion de TF-IDF en tabla\n",
    "hasattr(tfidf, \"toDF\")\n",
    "spark = SparkSession(sc)\n",
    "hasattr(tfidf, \"toDF\")\n",
    "tfidf.toDF([\"Token\",\"DocumentoID\",\"TF-IDF\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b860533",
   "metadata": {},
   "source": [
    "# N-GRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7291a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BIGRAMS(data):\n",
    "    # Tokenizamos y agrupamos en bigramas\n",
    "    bigrams = [b for l in data.collect() for b in zip(l.split(\" \")[:-1], l.split(\" \")[1:])]\n",
    "    \n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5409efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('el', 'es'),\n",
       " ('es', 'muy'),\n",
       " ('muy', 'bueno'),\n",
       " ('bueno', 'en'),\n",
       " ('en', 'mineria'),\n",
       " ('mineria', 'de'),\n",
       " ('de', 'datos'),\n",
       " ('el', 'sabe'),\n",
       " ('sabe', 'minerar'),\n",
       " ('minerar', 'datos'),\n",
       " ('datos', 'con'),\n",
       " ('con', 'librerias'),\n",
       " ('librerias', 'de'),\n",
       " ('de', 'datos')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos nuestra data de dos oraciones\n",
    "data=[\"el es muy bueno en mineria de datos\",\n",
    "      \"el sabe minerar datos con librerias de datos\"]\n",
    "\n",
    "# Volvemos este arreglo de tuplas en un RDD de 2 particiones\n",
    "oraciones=sc.parallelize(data,2)\n",
    "oraciones.collect()\n",
    "\n",
    "# BI-GRAMS\n",
    "bigrams = BIGRAMS(oraciones) # Aplicamos tf\n",
    "bigrams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
